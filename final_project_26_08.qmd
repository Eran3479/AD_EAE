---
title: "ADS Final Project <br>User Behavior & Course Completion"
author: "Einat Liron 318808813<br> Assaf Nissim 206500290 <br> Eran Tsur 207350901"
format: 
  revealjs:
    smaller: true
    transition: slide
    transition-speed: slow
    editor: visual
    number-sections: true
    toc: true
    toc-depth: 1
    scrollable: true
    slide-number: true
    incremental: true
    css: styles.css
---

# Introduction

In the rapidly expanding field of online education, understanding the factors that drive student engagement and course completion is crucial for optimizing learning experiences. Predicting online course engagement involves analyzing various aspects of user behavior, including interaction patterns, time spent on tasks, and the effectiveness of instructional design.

By identifying the key elements that contribute to successful course completion, educators and platform developers can tailor their approaches to meet the diverse needs of learners, ultimately improving retention rates and educational outcomes. This research focuses on exploring the intricate relationship between user behavior and course completion, aiming to enhance our understanding of what motivates students to persist and succeed in an online learning environment.

![](Picture.jpg){fig-align="center" width="6500"}

# Literature review

## Determining Factors in MOOCs Completion Rates: Application Test in Energy Sustainability Courses

**Introduction:**This study explores factors affecting Massive Open Online Course (MOOC) completion rates, specifically in energy sustainability courses. It examines how personal, family, social, labor, and instructional design factors influence engagement and course completion.

**Methods:** Data from 8,737 participants in 12 MOOCs (2017-2018) were analyzed. Surveys assessed participants’ motivations, backgrounds, and interactions to identify key factors influencing enrollment and completion.

**Results:** Personal, family, social, labor, and instructional design factors significantly impact MOOC engagement and completion. "Professional development" was most influential, particularly for technical graduates. Effective instructional design, including interactive elements and course relevance, was vital for younger participants, while traditional MOOC design correlated with lower completion rates.

**Conclusions:** Improving MOOC completion rates hinges on effective instructional design, strong personal motivation, and professional relevance. These insights are essential for educators and course designers seeking to boost MOOC effectiveness and engagement.

## Massive Open Online Course Completion Rates Revisited: Assessment, Length and Attrition

**Introduction:** This study updates Jordan's 2014 work by analyzing enrollment and completion data from 221 MOOCs to identify factors affecting completion rates amidst changing enrollment trends.

**Methods:** The analysis uses multiple regression to evaluate how course length, start date, and assessment type impact completion rates, with data showing rates from 0.7% to 52.1%.

**Results:** Longer courses and those using peer grading are associated with lower completion rates. Course length and early engagement are significant factors, while university ranking and total enrollment are not.

**Conclusions:** Course length and assessment type significantly affect MOOC completion rates. Further research is needed due to data limitations and evolving trends.

## Comparing the Factors That Predict Completion and Grades Among For-Credit and Open/MOOC Students in Online Learning

**Introduction:** This study compares the factors that predict course completion and grades among two groups of online learners: for-credit students and open/MOOC participants. The research aims to identify key engagement factors that influence completion rates.

**Methods:** The study analyzes engagement behaviors such as forum participation and the number of comments made by students to determine their impact on course completion for both for-credit and MOOC students.

**Results:** Active engagement in course activities, particularly forum participation, was a strong predictor of course completion for both for-credit and MOOC students. For-credit students' completion was more closely tied to these interactive elements, while MOOC students also showed similar patterns, though with slight variations.

**Conclusions:** The study emphasizes the critical role of active engagement in predicting successful course completion in both for-credit and MOOC contexts. The findings suggest that promoting interactive course elements could enhance completion rates across different types of online learning environments.

## Factors for Success and Course Completion in Massive Open Online Courses through the Lens of Participant Types

**Introduction:** This study provides insights into the factors affecting success and course completion in MOOCs by categorizing participants based on their involvement in course activities. It examines how participant categorization, interaction, and instructor effectiveness influence outcomes.

**Methods:** The research focuses on identifying participant types through diagnostic surveys and assessing the impact of interaction and instructor effectiveness on success and course completion.

**Results:** The study highlights the importance of participant categorization in understanding success factors in MOOCs. Interaction between students and instructors, as well as the instructor’s teaching style, were found to be critical for course completion. The study also notes limitations related to its focus on a single platform and reliance on qualitative data.

**Conclusions:** The findings provide a basis for designing more effective MOOCs by considering participant types, fostering interaction, and enhancing instructor effectiveness. The study suggests further research incorporating quantitative data, cultural differences, and broader stakeholder perspectives to deepen understanding of MOOC success factors

## Using a gamified mobile app to increase student engagement, retention and academic achievement

**Introduction**

This study explores the potential of a gamified mobile app to enhance student engagement, retention, and academic performance in higher education. The app was designed to deliver multiple-choice quizzes to students' mobile devices, reinforcing lecture content and encouraging continuous learning.

**Methods**

The app was introduced to students in a first-year accounting unit and several science units. Data on student retention rates, academic performance, and app usage were collected and analyzed to determine the app's impact.

**Results**

The introduction of the app was associated with a 12.23% improvement in student retention rates compared to previous cohorts. Students who used the app had an average grade 7.03% higher than those who did not use the app. A positive correlation (0.40) was found between students’ performance on the app and their academic grades.

**Conclusion**

The study suggests that the gamified mobile app may significantly improve student retention and academic performance. However, further research is needed to establish a causal relationship between app usage and these positive outcomes

## Conclusion from articles

The reviewed studies highlight that effective instructional design, personal motivation, and professional relevance are crucial for improving MOOC completion rates. Engaging course content, interactive elements, and alignment with participants' professional goals significantly enhance both engagement and success.

Additionally, the length of the course and the type of assessment methods used are pivotal, with shorter courses and varied assessments generally leading to higher completion rates. Active participation in course activities is a strong predictor of success. Future research should address the limitations of current studies by incorporating quantitative data, exploring cultural differences, and considering diverse stakeholder perspectives to further enhance MOOC design and implementation.

# Dataset description

The dataset to be analyzed provides a detailed snapshot of user engagement within an online course platform, offering valuable insights into the factors that influence course completion.

It includes a range of features that capture various aspects of user behavior and course interaction. These features include user demographics, such as unique identifiers and the type of device used, as well as course-specific data like the category of the course, time spent on the course, the number of videos watched, and the number of quizzes taken.

Additionally, the dataset provides metrics on quiz performance and completion rates, with the target variable indicating whether a user successfully completed the course. This comprehensive dataset enables a multifaceted analysis aimed at understanding how different engagement metrics contribute to the likelihood of course completion, providing a basis for optimizing educational strategies and improving learner outcomes.

# Hypothesis

***what do you think?***

How do different factors such as Time Spent on Course, Number of Videos Watched, Number of Quizzes Taken, Quiz Scores, Completion Rate, and Device Type influence the likelihood of Course Completion across various Course Categories?

In this research, we hypothesize that the likelihood of course completion will be most strongly influenced by **Completion Rate** and **Quiz Scores**, as these directly reflect a student's progress and understanding. **Time Spent on Course** and **Number of Videos Watched** are also expected to positively impact completion, though likely to a lesser extent. **Device Type** may have a moderate influence, with desktop users potentially showing higher completion rates than mobile users.

Among the parameters themselves, we anticipate a strong positive correlation between **Time Spent on Course** and **Number of Videos Watched**, as well as between **Quiz Scores** and **Completion Rate**. **Time Spent on Course** is also likely to be closely linked to **Number of Quizzes Taken**. These relationships will help identify the key drivers of successful course completion across different Course Categories.

# Methods- Overview

In this project, we conducted a thorough analysis, starting with data cleaning to ensure accuracy. We performed correlation tests to identify relationships between variables and used the Shapiro-Wilk test to check for normal distribution. We ran a logistic regression model as a non-parametric method to analyze the data. Additionally, we calculated various means to summarize the data and created graphs to visualize the connections between different variables. This approach provided us with a clear understanding of the relationships within the data.

## Loading the data and the necessary libraries

```{r, eval=FALSE, echo=TRUE}
install.packages("ggplot2")
install.packages("reshape2")
install.packages("corrplot")
install.packages("knitr")
install.packages("kableExtra")
```

```{r, results='hide', message=FALSE, echo=TRUE}

library(ggplot2)
library(reshape2)
library(dplyr)
library(tidyr)
library(tidyverse)
library(corrplot)
library(kableExtra)
library(MASS)
library(reshape2)
library(knitr)
library(broom)
```

```{r, echo=TRUE}
# Reading the file into R
data = read.csv("data.csv")
```

```{r, echo=TRUE}
# Convert to tibble
  data = as_tibble(data)
```

## Inspecting and cleaning the data

```{r, echo=TRUE}
# Insepecting the data
summary(data)
```

## Checking for NA's and removing unnecessary columns and rows

```{r, echo=TRUE}
#Check for NA's
sapply(data, function(x) sum(is.na(x))) # NO NA's
```

the UserID column was removed as it is not necessary for the data analysis.

```{r, echo=TRUE}
# Remove UserID column
data = dplyr::select(data, -UserID)
```

## Checking for NA's and removing unnecessary columns and rows

All of the duplicated observations were also removed by executing the following code:

```{r, echo=TRUE}
# Check for duplicates
duplicates = data[duplicated(data), ] # 877 duplicated rows
duplicates
```

```{r, echo=TRUE}
#Removing duplicates
data = data |>
  distinct()
```

```{r, echo=TRUE}
#Check to see if the duplicates were removed, should equal to 0
sum(duplicated(data)) # 0 
```

## Normalizing the data

normalizing the parameters' values to a range of 0-1 for the ease of work:

```{r, echo=TRUE}
# Function to normalize columns
normalize = function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}
```

```{r, echo=TRUE}
# Normalize the specified columns
data = data |>
  mutate(TimeSpentOnCourse = normalize(TimeSpentOnCourse),
         NumberOfVideosWatched = normalize(NumberOfVideosWatched),
         NumberOfQuizzesTaken = normalize(NumberOfQuizzesTaken),
         QuizScores = normalize(QuizScores),
         CompletionRate = normalize(CompletionRate))

# Rounding the decimal numbers
data = data |>
  mutate(across(where(is.numeric) & !all_of(c("DeviceType")), round, 3))

# View the normalized data
head(data)
```

## Reducing observations

Reducing the number of observations from each course category so it doesn't affect our analysis:

```{r, echo=TRUE}
# count how many students from each category
category = data |>
  group_by(CourseCategory) |>
  summarise(Count = n())
```

```{r, echo=TRUE}
# Subset 1500 records from each course category randomly
set.seed(123)

data = data |>  
  group_by(CourseCategory) |>
  sample_n(1500)

# Rounding the decimel numbers
data = data |>
  mutate(across(where(is.numeric) & !all_of(c("DeviceType")), round, 3))
```

## Correlation test

A correlation test was used to measure the strength and direction of the relationship between the variables, helping us to determine how changes in each parameter are associated with changes in the target variable (course completion)

```{r, echo=TRUE, results='hide'}
#Calculate correlation for each course category between target variable
#(course completion) and the rest of the variables
cor_with_p = data |>
  group_by(CourseCategory) |>
  summarise(across(c(TimeSpentOnCourse, NumberOfVideosWatched, 
                     NumberOfQuizzesTaken, QuizScores,DeviceType, CompletionRate), 
                   ~ list(correlation = cor(.x, CourseCompletion),
                          p_value = cor.test(.x, CourseCompletion)$p.value))) |>
  unnest(cols = c(TimeSpentOnCourse, NumberOfVideosWatched, 
                  NumberOfQuizzesTaken, QuizScores, CompletionRate, DeviceType))
```

## Correlation test visualization

Next, we wanted to visualize the correlation so it would be easier to see which parameter in each course category has the highest correlation with course completion (the darker the shade- the higher the correlation is):

```{r, echo=TRUE, results='hide'}

# Create the correlation table 
cor_table = data.frame(
  CourseCategory = c("Arts", "Business", "Health", "Programming", "Science"),
  TimeSpentOnCourse = c(0.184, 0.220, 0.160, 0.175, 0.198),
  NumberOfVideosWatched = c(0.248, 0.241, 0.224, 0.194, 0.265),
  NumberOfQuizzesTaken = c(0.335, 0.276, 0.274, 0.261, 0.284),
  QuizScores = c(0.315, 0.316, 0.311, 0.302, 0.278),
  CompletionRate = c(0.303, 0.328, 0.346, 0.371, 0.314),
  DeviceType = c(-0.022, -0.022, -0.022, 0.032, 0.019)
)  

# Function to create green shades based on values
green_shades = function(values) {
  green_palette = colorRampPalette(c("#e6ffe6", "#006400"))(100) # Light green to dark green
  green_palette[as.numeric(cut(values, breaks = 100))]
}

# Apply green shades to each numeric column individually
cor_table |>
  kbl() |>
  kable_styling(
    full_width = FALSE, 
    font_size = 17,  
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  ) |>
  column_spec(2, background = green_shades(cor_table$TimeSpentOnCourse)) |>
  column_spec(3, background = green_shades(cor_table$NumberOfVideosWatched)) |>
  column_spec(4, background = green_shades(cor_table$NumberOfQuizzesTaken)) |>
  column_spec(5, background = green_shades(cor_table$QuizScores)) |>
  column_spec(6, background = green_shades(cor_table$CompletionRate)) |>
  column_spec(7, background = green_shades(cor_table$DeviceType)) |>
  column_spec(2:7, width = "9em") 

```

## Correlation matrices

Additionally, we checked the correlations results between all variables to to gain a deeper understanding of the relationships between them:

```{r, echo=TRUE, results='hide'}
#A loop for the 5 matrices
#Matrices Visualization
# plotting area
par(mfrow = c(2, 3))

for (category in unique(data$CourseCategory)) {
  cat("\nCorrelation Matrix for:", category, "\n")
  
  # Filter
  category_data = data |>
    filter(CourseCategory == category) |>
    ungroup() |>
    dplyr::select(TimeSpentOnCourse, NumberOfVideosWatched, 
           NumberOfQuizzesTaken, QuizScores, 
           CompletionRate,DeviceType, CourseCompletion)
  
  # Calculate correlation matrix
  corr_matrix = cor(category_data)
  
  # adding values and colors
  corrplot(corr_matrix, method = "color", 
           addCoef.col = "black", # Add correlation coefficient values in black
           number.cex = 1, # Correlation number size
           tl.cex = 0.8, # Text label size
           tl.col = "black", # text labels black
           title = category, 
           cl.cex = 0.8, # legend size
           col = colorRampPalette(c("blue", "white", "purple"))(200)) 
}


```

## Shapiro-Wilk normality test

For examining normal distribution per parameter within each course category, we used the **Shapiro-Wilk normality test**:

```{r, echo=TRUE, results='hide'}

#all of the results are < 0.05, meaning none of them follow a normal distribution
# List of numeric columns to test
numeric_columns = c("TimeSpentOnCourse", "NumberOfVideosWatched", 
                    "NumberOfQuizzesTaken", "QuizScores", 
                    "CompletionRate", "DeviceType", "CourseCompletion")

# Loop through each course category
for (category in unique(data$CourseCategory)) {
  cat("\nNormality Tests for:", category, "\n")
  
  # Filter data for the current category
  category_data = data |>
    filter(CourseCategory == category) |>
    dplyr::select(all_of(numeric_columns))  # Select only numeric columns
  
  # Apply Shapiro-Wilk test to each numeric column
  for (col in numeric_columns) {
    cat("\nColumn:", col, "\n")
    shapiro_result = shapiro.test(category_data[[col]])
    print(shapiro_result)
  }
}

```

Creating a data frame to display the results:

```{r, echo=TRUE, results='hide'}

data_fm = data.frame(
  "Course category" = c("Arts", "Business", "Health", "Programming", "Science"),
  "Time spent on course" = "P-value < 0.05",
  "Number of videos watched" = "P-value < 0.05",
  "Number of quizzes taken" = "P-value < 0.05",
  "Quiz scores" = "P-value < 0.05",
  "Completion rate" = "P-value < 0.05",
  "Device Type" = "P-value < 0.05",
  "Course completion" = "P-value < 0.05"
)

# Create the table 
data_fm |>
  kable("html", align = 'c') |>
  kable_styling(
    full_width = FALSE, 
    font_size = 14,  
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  ) |>
  add_header_above(c(" " = 1, "Parameter" = 7)) |>
  column_spec(2:8, width = "9em") 
```

## Histogram plotting

Additionally, we plotted histograms to further inspect the data distribution's type:

```{r, echo=TRUE, results='hide'}

# Pivot the data to long format for easier plotting with ggplot2
data_long = data |>
  dplyr::select(CourseCategory, all_of(numeric_columns)) |>
  pivot_longer(cols = all_of(numeric_columns), names_to = "Variable", values_to = "Value")

# Create histograms for each variable and course category
hist = ggplot(data_long, aes(x = Value)) +
  geom_histogram(binwidth = 1, fill = "purple", color = "black", alpha = 0.7) +
  facet_grid(CourseCategory ~ Variable, scales = "free_x") +
  labs(title = "Histograms of Numeric Variables by Course Category",
       x = "Value",
       y = "Frequency") +
  theme_minimal()
```

## Logistic regression model

The following code shows a logistic regression model to predict whether a course will be completed based on the parameters and then summarizes the model, showing how each parameter influences the likelihood of course completion. The summary includes statistical details like coefficients, significance levels, and model fit measures.

```{r, echo=TRUE, results='hide'}
# logistic regression model
logistic_model = glm(CourseCompletion ~ CourseCategory + TimeSpentOnCourse + 
                        NumberOfVideosWatched + NumberOfQuizzesTaken + 
                        QuizScores + CompletionRate, 
                      data = data, family = binomial)

```

## Predicted probabilities plot

A plot showing the predicted probabilities of course completion for different course categories, based on Fridman model.

```{r, echo=TRUE, results='hide'}
# Predict probabilities based on the model
data$predicted_prob = predict(logistic_model, type = "response")

# Visualize
predict_p = ggplot(data, aes(x = CourseCategory, y = predicted_prob)) +
  geom_boxplot() +
  labs(y = "Predicted Probability of Course Completion",
       x = "Course Category",
       title = "Predicted Probability by Course Category",
       subtitle = "Logistic Regression Model on Course Completion") +
  theme_minimal()
```

## Forest plot

A forest plot showing the odds ratios with 95% confidence intervals for each predictor in the logistic regression model.

```{r, echo=TRUE,results='hide'}

# tidy version of the model results
tidy_model = tidy(logistic_model, conf.int = TRUE, exp = TRUE)

# Filter out the intercept for a cleaner plot
tidy_model = tidy_model[tidy_model$term != "(Intercept)", ]

# Plot the odds ratios
prediced_a = ggplot(tidy_model, aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +  #for better readability
  labs(y = "Odds Ratio", x = "Predictor",
       title = "Odds Ratios with 95% Confidence Intervals",
       subtitle = "Logistic Regression Model on Course Completion") +
  theme_minimal()
```

## Chi- Test: Device Type and Course Completion

We chose to examine the **Device type** parameter separately since it is a binary variable, using Chi- Test. This will determine whether there is a significant association between **Course completion** and **Device type** by comparing the observed frequencies in each category to the expected frequencies if the variables were independent.

```{r, echo=TRUE, results='hide'}
chi_test_results = data |>
  group_by(CourseCategory) |>
  summarise(
    Chi_Square_Test = list(chisq.test(table(DeviceType, CourseCompletion)))
  )

# Display the p-values for each course category
results =chi_test_results |>
  mutate(p_value = sapply(Chi_Square_Test, function(x) x$p.value)) |>
  dplyr:: select(CourseCategory, p_value)


```

Chi- Test visualization:

```{r, echo=TRUE, results='hide'}
ggplot(results, aes(x = CourseCategory, y = p_value)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_hline(yintercept = 0.05, color = "red", linetype = "dashed") +  # Red line at 0.05
  geom_text(aes(label = round(p_value, 3)), vjust = 0) +
  theme_minimal() +
  labs(title = "Chi-Square Test p-values by Course Category",
       x = "Course Category",
       y = "p-value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Calculating Odds Ratio by Device Type and Course Completion

The odds ratio is a measure of the likelihood of course completion associated with using a smartphone compared to a computer. An odds ratio greater than 1 suggests that users on smartphones have higher odds of completing a course compared to those on computers. Conversely, an odds ratio less than 1 indicates that smartphone users have lower odds of completing a course relative to computer users.

```{r, echo=TRUE, results='hide'}
health_data_ratio <- data %>% filter(CourseCategory == "Health")
model_health <- glm(CourseCompletion ~ DeviceType, data = health_data_ratio, family = binomial)


odds_ratio_health <- exp(coef(model_health))
```

```{r, echo=TRUE, results='hide'}

# Business:
Business_data_ratio <- data %>% filter(CourseCategory == "Business")


model_business <- glm(CourseCompletion ~ DeviceType, data = Business_data_ratio, family = binomial)



odds_ratio_business <- exp(coef(model_business))
```

```{r, echo=TRUE, results='hide'}
## Arts:

arts_data_ratio <- data %>% filter(CourseCategory == "Arts")


model_arts <- glm(CourseCompletion ~ DeviceType, data = arts_data_ratio, family = binomial)



odds_ratio_arts <- exp(coef(model_arts))
```

```{r, echo=TRUE, results='hide'}
## Programming: 

programming_data_ratio <- data %>% filter(CourseCategory == "Programming")


model_programming <- glm(CourseCompletion ~ DeviceType, data = programming_data_ratio, family = binomial)



odds_ratio_programming <- exp(coef(model_programming))
```

```{r, echo=TRUE, results='hide'}
## Science:

science_data_ratio <- data %>% filter(CourseCategory == "Science")


model_science <- glm(CourseCompletion ~ DeviceType, data = science_data_ratio, family = binomial)



odds_ratio_science <- exp(coef(model_science))

```

## Percentage of Course completion by category

We calculated the Course Completion percentage across all course categories

```{r, echo=TRUE, results='hide', fig.show='hide'}
data_health = data|>
  filter(CourseCategory == 'Health')

data_arts = data |>
  filter(CourseCategory == 'Arts')

data_science <- data %>%
  filter(CourseCategory== 'Science')

data_Programming <- data %>%
  filter(CourseCategory == 'Programming')

data_business <- data %>%
  filter(CourseCategory == 'Business')
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
calculate_completion <- function(data) {
  completion <- sum(data$CourseCompletion == 1) / 1500
  return(completion)
}

# Calculate completion rates for each category
completion_health <- calculate_completion(data_health)
completion_science <- calculate_completion(data_science)
completion_Programming <- calculate_completion(data_Programming)
completion_arts <- calculate_completion(data_arts)
completion_business <- calculate_completion(data_business)
```

```{r, echo=TRUE, results='hide', fig.show='hide',dev='svg'}
completion_rates <- tibble(
  course = c("Health", "Science", "Programming", "Arts", "Business"),
  completion_rate = c(completion_health, 
                      completion_science, 
                      completion_Programming,
                      completion_arts,
                      completion_business))
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
completion_rates_per = completion_rates %>%
  mutate(completion_rate = completion_rate * 100)
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
# Create the bar chart
ggplot(completion_rates_per, aes(x = course, y = completion_rate, fill = course)) +
  geom_bar(stat = 'identity') +
  geom_text(aes(label = round(completion_rate, 1)), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(scale = 1), limits = c(0, 100)) +
  labs(title = " Course Completion by Category",
       x = "Course Category",
       y = "completion of course (pass/not pass) (%)") +
  theme_minimal() +
  theme(legend.position = "none")+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Mean by Variables

Next, We calculated the average of all course categories by variables

```{r, echo=TRUE, results='hide'}
mean_data <- data %>%
  dplyr:: select (-DeviceType, -CourseCompletion) %>%
  group_by(CourseCategory) %>%
  summarise(across(everything(), mean, na.rm = TRUE))

# Pivot data for easier plotting
mean_data_long <- mean_data %>%
  pivot_longer(-CourseCategory, names_to = "Variable", values_to = "Mean")

by_varibles = ggplot(mean_data_long, aes(x = CourseCategory, y = Mean, fill = CourseCategory)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(Mean, 2)), vjust = -0.5, size = 3) +  # Add mean values on top of the bars
  facet_wrap(~ Variable, scales = "free_y") +
  scale_y_continuous(limits = c(0, 1)) +
  theme_minimal() +
  labs(title = "Mean Comparison Across Categories for Each Variable", 
       x = "Course Category", 
       y = "Mean Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )

```

## Percentage of users by Device Type

We calculated the percentage of users for each device type within each course category to inspect its influence on course completion:

```{r, echo=TRUE, results='hide'}
device_data <- data %>%
      group_by(CourseCategory, DeviceType) %>%
      summarise(UserCount = n()) %>%
      ungroup()
    
    # Calculate the percentage of users for each device type within each course category
    device_data <- device_data %>%
      group_by(CourseCategory) %>%
      mutate(Percentage = (UserCount / sum(UserCount)) * 100) %>%
      ungroup()
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
    # Create the faceted bar graph
    ggplot(device_data, aes(x = as.factor(DeviceType), y = Percentage, fill = as.factor(DeviceType))) +
      geom_bar(stat = "identity") +
      geom_text(aes(label = paste0(round(Percentage, 1), "%")), vjust = -0.5, size = 3) + 
      facet_wrap(~ CourseCategory) +
      scale_y_continuous(limits = c(0, 100), labels = scales::percent_format(scale = 1)) + 
      theme_minimal() +
      labs(title = "Percentage of Users by Device Type Across Course Categories", 
           x = "Device Type", 
           y = "Percentage of Users") +
      theme(axis.text.x = element_text(angle = 0, hjust = 1)) +
      scale_fill_manual(values = c("0" = "#1f77b4", "1" = "#ff7f0e"), 
                        name = "Device Type",
                        labels = c("Device 0", "Device 1"))+
      theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Examining the relationships between different parameters

We chose a few parameters that we assumed the relationship between them affects **Course Completion** significantly.

## Density calculation

we are calculating the density of the points to present only the points that have high density (top 20%) to show the 'chunks' of points that are similar to each other, which will hopefully help us to understand the relationship between them and the course completion.

```{r, echo=TRUE, results='hide'}
calculate_density = function(x, y) {
  dens = kde2d(x, y, n = 100)
  ix = findInterval(x, dens$x)
  iy = findInterval(y, dens$y)
  return(dens$z[cbind(ix, iy)])
}

```

## Time spent on course compared to Completion Rate

```{r, echo=TRUE, results='hide', fig.show='hide'}
# Calculate densities for not completed and completed data
notcompleted1 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, CompletionRate))

completed1 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, CompletionRate))
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
highdensity_combined1 <- bind_rows(
  notcompleted1 %>% mutate(Status = "Not Completed"),
  completed1 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion, TimeSpentOnCourse, CompletionRate, density, Status)
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
# Plot the most dense areas
ggplot(highdensity_combined1, aes(x = TimeSpentOnCourse, y = CompletionRate, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "Time Spent on Course",
       y = "Completion Rate",
       color = "Completion Status") +
  theme_minimal()+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Quiz Score compared to Completion Rate

```{r, echo=TRUE, results='hide', fig.show='hide'}
notcompleted2 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(QuizScores, CompletionRate))

completed2 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(QuizScores, CompletionRate))
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
highdensity_combined2 <- bind_rows(
  notcompleted2 %>% mutate(Status = "Not Completed"),
  completed2 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion, QuizScores, CompletionRate, density, Status)
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
# Plot the most dense areas
ggplot(highdensity_combined2, aes(x = QuizScores, y = CompletionRate, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "Quiz scores",
       y = "Completion Rate",
       color = "Completion Status") +
  theme_minimal()+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Number of Quiz Taken compared to Quiz Score

```{r, echo=TRUE, results='hide'}
notcompleted3 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(NumberOfQuizzesTaken, QuizScores))

completed3 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(NumberOfQuizzesTaken, QuizScores))
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
highdensity_combined3 <- bind_rows(
  notcompleted3 %>% mutate(Status = "Not Completed"),
  completed3 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion ,NumberOfQuizzesTaken , QuizScores, density, Status)
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
# Plot the most dense areas
ggplot(highdensity_combined3, aes(x = NumberOfQuizzesTaken, y = QuizScores, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "Number Of Quizzes Taken",
       y = "Quizzes Scores",
       color = "Completion Status") +
  theme_minimal() +
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )

```

## Time spent on course compared to Quiz Score

```{r, echo=TRUE, results='hide'}
notcompleted4 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, QuizScores))

completed4 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, QuizScores))
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
highdensity_combined4 <- bind_rows(
  notcompleted4 %>% mutate(Status = "Not Completed"),
  completed4 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion ,TimeSpentOnCourse , QuizScores, density, Status)
```

```{r, echo=TRUE, results='hide', fig.show='hide'}
# Plot the most dense areas
ggplot(highdensity_combined4, aes(x = TimeSpentOnCourse , y = QuizScores, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "TimeSpentOnCourse",
       y = "Quizes scores",
       color = "Completion Status") +
  theme_minimal()+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Methodology - Summary of codes and functions

● **read.csv:** Reads a CSV (Comma Separated Values) file into a dataframe in R.

● **summary:** Generates a summary of a data frame, providing statistics such as mean, median, min, max, and quartiles for each column.

● **dplyr functions**: A set of tools for data manipulation, allowing easy filtering, summarizing, and transforming data.

● **mean:** Calculates the arithmetic mean of a numeric vector.

● **cor.test:** Performs a correlation test between two numeric vectors, providing the correlation coefficient and p-value.

● **Shapiro.test:** Conducts a Shapiro-Wilk test to check for normality in a numeric vector, providing a p-value.

● **matrices:** Structured arrays of numbers arranged in rows and columns, commonly used in statistical tests and analyses, such as correlation matrices, to represent and compute relationships between multiple variables simultaneously.

● **ggplot:** A powerful package for creating complex and customizable data visualizations using a layered approach.

● **Logistic regression model:** A statistical method used to predict the probability of a binary outcome (such as yes/no) based on one or more predictor variables.

● **Chi- square test:** A statistical test that assesses the association between categorical variables by comparing observed and expected frequencies.

● **Odds ratio:** A measure of association between two variables, indicating the odds of an outcome occurring with a particular exposure versus without it.

# Main results

## Correlation analysis

Correlation test between course completion and each parameter:

● P- value lower than 0.05 means highly significant;

● A correlation coefficient, which measures the strength and direction of the linear relationship between two variables;

● The closer the correlation is to 1 (positive) or -1 (negative), the stronger the linear relationship. A value closer to 0 indicates a weaker linear relationship.

## Correlation test between course completion and each parameter:

The green shades table highlights the correlations between various parameters and **Course Completion** across all course categories.

```{r, echo=FALSE}

# Create the correlation table 
cor_table = data.frame(
  CourseCategory = c("Arts", "Business", "Health", "Programming", "Science"),
  TimeSpentOnCourse = c(0.184, 0.220, 0.160, 0.175, 0.198),
  NumberOfVideosWatched = c(0.248, 0.241, 0.224, 0.194, 0.265),
  NumberOfQuizzesTaken = c(0.335, 0.276, 0.274, 0.261, 0.284),
  QuizScores = c(0.315, 0.316, 0.311, 0.302, 0.278),
  CompletionRate = c(0.303, 0.328, 0.346, 0.371, 0.314),
  DeviceType = c(-0.022, -0.022, -0.022, 0.032, 0.019)
)  

# Function to create green shades based on values
green_shades = function(values) {
  green_palette = colorRampPalette(c("#e6ffe6", "#006400"))(100) # Light green to dark green
  green_palette[as.numeric(cut(values, breaks = 100))]
}

# Apply green shades to each numeric column individuallyr
cor_table |>
  kbl() |>
  kable_styling(
    full_width = FALSE, 
    font_size = 17,  
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  ) |>
  column_spec(2, background = green_shades(cor_table$TimeSpentOnCourse)) |>
  column_spec(3, background = green_shades(cor_table$NumberOfVideosWatched)) |>
  column_spec(4, background = green_shades(cor_table$NumberOfQuizzesTaken)) |>
  column_spec(5, background = green_shades(cor_table$QuizScores)) |>
  column_spec(6, background = green_shades(cor_table$CompletionRate)) |>
  column_spec(7, background = green_shades(cor_table$DeviceType)) |>
  column_spec(2:7, width = "9em") 
```

The highest correlation is observed in the **Programming** category between **CompletionRate** and **CourseCompletion** (0.371), indicating a moderate positive relationship. In contrast, the **Arts** category shows a lower correlation between **TimeSpentOnCourse** and **CourseCompletion** (0.184), suggesting a weaker influence.

Overall, **CompletionRate** consistently shows the strongest correlation with **CourseCompletion** across all categories, with values such as 0.328 in **Business** and 0.346 in **Health**. This suggests that **CompletionRate** is a key factor influencing course completion. For **DeviceType**, the correlations were negligible and not significant across all course categories, with values close to zero.

In addition to the correlation coefficients, the corresponding **P-values** were also tested, almost all of which are extremely low (\< 0.05)**.** These low p-values indicate that the correlations are statistically significant, meaning that the relationships observed between the parameters and Course Completion are unlikely to be due to random chance. However, the p-values for **DeviceType** in the **Business, Health,** and **Programming** categories are above 0.05, meaning they are not statistically significant.

## Correlation Matrices

The correlation matrices across all course categories reveal generally weak relationships between the parameters themselves.

For instance, in the **Business** category, the correlation between **NumberOfVideosWatched** and **TimeSpentOnCourse** is only 0.6, and in the **Health** category, **NumberOfVideosWatched** and **QuizScores** show a correlation of -0.05. These weak correlations indicate that the parameters, such as **TimeSpentOnCourse**, **NumberOfVideosWatched**, and **QuizScores**, are largely independent of one another within each course category, with minimal influence on one another.

```{r, echo=FALSE, results='asis', fig.width=10, fig.height=8}
#A loop for the 5 matrices
#Matrices Visualization

# plotting area
par(mfrow = c(2, 3))

for (category in unique(data$CourseCategory)) {
  cat(".")
  
  # Filter
  category_data = data |>
    filter(CourseCategory == category) |>
    ungroup() |>
    dplyr::select(TimeSpentOnCourse, NumberOfVideosWatched, 
           NumberOfQuizzesTaken, QuizScores, 
           CompletionRate,DeviceType, CourseCompletion)
  
  # Calculate correlation matrix
  corr_matrix = cor(category_data)
  
  # adding values and colors
  corrplot(corr_matrix, method = "color", 
           addCoef.col = "black", # Add correlation coefficient values in black
           number.cex = 1, # Correlation number size
           tl.cex = 0.8, # Text label size
           tl.col = "black", # text labels black
           title = category,
           mar = c(0, 0, 2, 0),
           cl.cex = 0.8, # legend size
           col = colorRampPalette(c("blue", "white", "purple"))(200)) 
}
```

## Shapiro-Wilk Normality Test

**Shapiro-Wilk normality test:** used to examine the normal distribution of each parameter within each course category. The results indicate which statistical tests are appropriate based on the type of distribution.

```{r, echo=FALSE}


data_fm = data.frame(
  "Course category" = c("Arts", "Business", "Health", "Programming", "Science"),
  "Time spent on course" = "P-value < 0.05",
  "Number of videos watched" = "P-value < 0.05",
  "Number of quizzes taken" = "P-value < 0.05",
  "Quiz scores" = "P-value < 0.05",
  "Completion rate" = "P-value < 0.05",
  "Device Type" = "P-value < 0.05",
  "Course completion" = "P-value < 0.05"
)

# Create the table 
data_fm |>
  kable("html", align = 'c') |>
  kable_styling(
    full_width = FALSE, 
    font_size = 14,  
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  ) |>
  add_header_above(c(" " = 1, "Parameter" = 7)) |>
  column_spec(2:8, width = "9em")  

```

All the parameters have p-values lower than 0.05, indicating that **none of them are normally distributed.**

## Histogram Plotting

We also plotted histograms to further examine the distribution types:

```{r, echo=FALSE}
# Additional test for a normal distribution, plotting histograms

# Pivot the data to long format for easier plotting with ggplot2
data_long = data |>
  dplyr::select(CourseCategory, all_of(numeric_columns)) |>
  pivot_longer(cols = all_of(numeric_columns), names_to = "Variable", values_to = "Value")

# Create histograms for each variable and course category
ggplot(data_long, aes(x = Value)) +
  geom_histogram(binwidth = 1, fill = "purple", color = "black", alpha = 0.7) +
  facet_grid(CourseCategory ~ Variable, scales = "free_x") +
  labs(title = "Histograms of Numeric Variables by Course Category",
       x = "Value",
       y = "Frequency") +
  theme_minimal()
```

It can be observed that the shapes of the histograms **do not resemble a normal distribution.**

## Logistic regression model

```{r, echo=FALSE}
# logistic regression model
logistic_model = glm(CourseCompletion ~ CourseCategory + TimeSpentOnCourse + 
                        NumberOfVideosWatched + NumberOfQuizzesTaken + 
                        QuizScores + CompletionRate, 
                      data = data, family = binomial)

# Display the summary
summary(logistic_model)
```

1.  **Significant Predictors**:

    -   **TimeSpentOnCourse**: More time spent on the course increases the likelihood of completion.
    -   **NumberOfVideosWatched**: Watching more videos significantly increases the odds of completing the course.
    -   **NumberOfQuizzesTaken**: Taking more quizzes is strongly associated with a higher completion rate.
    -   **QuizScores**: Higher quiz scores increase the probability of course completion.
    -   **CompletionRate**: A higher completion rate of course activities is associated with an increased likelihood of completing the course.

2.  **Course Category**:

    -   Being in the **Health** category reduces the odds of course completion compared to the baseline category. This is statistically significant.

    -   The **Business**, **Programming**, and **Science** categories do not show statistically significant differences in completion odds compared to the baseline.

    Overall, the model indicates that engagement metrics (time spent, videos watched, quizzes taken and scored, and overall completion rate) are crucial factors for predicting course completion.

## Predicted probabilities plot

```{r, echo=FALSE}
# Predict probabilities based on the model
data$predicted_prob = predict(logistic_model, type = "response")

# Visualize
ggplot(data, aes(x = CourseCategory, y = predicted_prob)) +
  geom_boxplot() +
  labs(y = "Predicted Probability of Course Completion",
       x = "Course Category",
       title = "Predicted Probability by Course Category",
       subtitle = "Logistic Regression Model on Course Completion") +
  theme_minimal()
```

The boxplot visualization shows that, while there is some variation in predicted probabilities across different course categories, most categories show similar distributions of predicted probabilities. The **Health** category appears to have a slightly lower median, which matches the statistical findings from the Logistic regression modell.

## Forest plot

```{r, echo=FALSE}
# tidy version of the model results
tidy_model = tidy(logistic_model, conf.int = TRUE, exp = TRUE)

# Filter out the intercept for a cleaner plot
tidy_model = tidy_model[tidy_model$term != "(Intercept)", ]

# Plot 
ggplot(tidy_model, aes(x = term, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +  # Flip coordinates for better readability
  labs(y = "Odds Ratio", x = "Predictor",
       title = "Odds Ratios with 95% Confidence Intervals",
       subtitle = "Logistic Regression Model on Course Completion") +
  theme_minimal()
```

## Forest plot- results explanation

**TimeSpentOnCourse**, **QuizScores**, **NumberOfVideosWatched**, **NumberOfQuizzesTaken**, and **CompletionRate** all have odds ratios significantly greater than 1, indicating these predictors are strongly associated with higher odds of course completion. - The confidence intervals for these variables do not cross 1, confirming their statistical significance.

**CourseCategory** variables (Science, Programming, Health, Business) have odds ratios close to 1, indicating they do not significantly affect the odds of course completion. Their confidence intervals also cross 1, further supporting their lack of statistical significance.

The plot visually confirms that engagement-related variables (time spent, quizzes, videos, scores, and completion rate) have a significant positive effect on course completion odds, while course category differences are not statistically significant, except for **Health** which might show a slight decrease but is not a strong predictor.

## Chi Test to test the connection between Device Type and Course Completion

```{r, echo=FALSE,results='hide'}
chi_test_results = data |>
  group_by(CourseCategory) |>
  summarise(
    Chi_Square_Test = list(chisq.test(table(DeviceType, CourseCompletion)))
  )

# Display the p-values for each course category
chi_test_results |>
  mutate(p_value = sapply(Chi_Square_Test, function(x) x$p.value)) |>
  dplyr:: select(CourseCategory, p_value)

```

```{r, echo= FALSE}
ggplot(results, aes(x = CourseCategory, y = p_value)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_hline(yintercept = 0.05, color = "red", linetype = "dashed") +  # Red line at 0.05
  geom_text(aes(label = round(p_value, 3)), vjust = 0) +
  theme_minimal() +
  labs(title = "Chi-Square Test p-values by Course Category",
       x = "Course Category",
       y = "p-value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Odds Ratio by Device Type and Course Completion

Across **all course categories** analyzed, the p-values indicate that **there is no statistically significant relationship between device type (smartphone vs. computer) and course completion rates**. While there are some variations in odds ratios, none of these differences are strong enough to be considered meaningful. Therefore, based on this data, **neither smartphones nor computers can be conclusively deemed better or worse for course completion** across these categories.

```{r,echo=FALSE}
health_data_ratio <- data %>% filter(CourseCategory == "Health")
model_health <- glm(CourseCompletion ~ DeviceType, data = health_data_ratio, family = binomial)


odds_ratio_health <- exp(coef(model_health))
print(odds_ratio_health)

# Business:
Business_data_ratio <- data %>% filter(CourseCategory == "Business")


model_business <- glm(CourseCompletion ~ DeviceType, data = Business_data_ratio, family = binomial)



odds_ratio_business <- exp(coef(model_business))
print(odds_ratio_business)

## Arts:

arts_data_ratio <- data %>% filter(CourseCategory == "Arts")


model_arts <- glm(CourseCompletion ~ DeviceType, data = arts_data_ratio, family = binomial)



odds_ratio_arts <- exp(coef(model_arts))
print(odds_ratio_arts)

## Programming: 

programming_data_ratio <- data %>% filter(CourseCategory == "Programming")


model_programming <- glm(CourseCompletion ~ DeviceType, data = programming_data_ratio, family = binomial)



odds_ratio_programming <- exp(coef(model_programming))
print(odds_ratio_programming)

## Science:

science_data_ratio <- data %>% filter(CourseCategory == "Science")


model_science <- glm(CourseCompletion ~ DeviceType, data = science_data_ratio, family = binomial)



odds_ratio_science <- exp(coef(model_science))
print(odds_ratio_science)
```

## Percentage of Course completion by category

**The bar graph shows the percentage of the student that completed the course by their course category.**

In all course category the completing percentage is bellow 50 %, which is low. the course with the highest percentage is Programming and the lowest is Health.

```{r, echo=FALSE}
data_health = data|>
  filter(CourseCategory == 'Health')

data_arts = data |>
  filter(CourseCategory == 'Arts')

data_science <- data %>%
  filter(CourseCategory== 'Science')

data_Programming <- data %>%
  filter(CourseCategory == 'Programming')

data_business <- data %>%
  filter(CourseCategory == 'Business')

calculate_completion <- function(data) {
  completion <- sum(data$CourseCompletion == 1) / 1500
  return(completion)
}

# Calculate completion rates for each category
completion_health <- calculate_completion(data_health)
completion_science <- calculate_completion(data_science)
completion_Programming <- calculate_completion(data_Programming)
completion_arts <- calculate_completion(data_arts)
completion_business <- calculate_completion(data_business)

completion_rates <- tibble(
  course = c("Health", "Science", "Programming", "Arts", "Business"),
  completion_rate = c(completion_health, 
                      completion_science, 
                      completion_Programming,
                      completion_arts,
                      completion_business))
completion_rates_per = completion_rates %>%
  mutate(completion_rate = completion_rate * 100)

# Create the bar chart
ggplot(completion_rates_per, aes(x = course, y = completion_rate, fill = course)) +
  geom_bar(stat = 'identity') +
  geom_text(aes(label = round(completion_rate, 1)), vjust = -0.5, size = 3.5) +
  scale_y_continuous(labels = scales::percent_format(scale = 1), limits = c(0, 100)) +
  labs(title = " Course Completion by Category",
       x = "Course Category",
       y = "completion of course (pass/not pass) (%)") +
  theme_minimal() +
  theme(legend.position = "none")+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )

```

## Mean by variables

The mean values of the analyzed variables indicate a high degree of **uniformity** across all course categories. This suggests that, regardless of the subject, **students tend to exhibit similar behaviors in terms of course completion, engagement with quizzes and videos, and time spent on the courses.** The slight variations observed, such as in quiz scores and the number of videos watched, may not be substantial enough to indicate any significant differences in student performance or engagement across different subjects.

```{r, echo=FALSE}
mean_data <- data %>%
  dplyr:: select (-DeviceType, -CourseCompletion) %>%
  group_by(CourseCategory) %>%
  summarise(across(everything(), mean, na.rm = TRUE))

# Pivot data for easier plotting
mean_data_long <- mean_data %>%
  pivot_longer(-CourseCategory, names_to = "Variable", values_to = "Mean")

ggplot(mean_data_long, aes(x = CourseCategory, y = Mean, fill = CourseCategory)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(Mean, 2)), vjust = -0.5, size = 3) +  # Add mean values on top of the bars
  facet_wrap(~ Variable, scales = "free_y") +
  scale_y_continuous(limits = c(0, 1)) +
  theme_minimal() +
  labs(title = "Mean Comparison Across Categories for Each Variable", 
       x = "Course Category", 
       y = "Mean Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Percentage of users by Device Type

The use of computers and smartphones is generally **balanced across all course categories**, with **no strong preference for one device type over the other**. In the Business and Health categories, there is a slight tendency for users to favor smartphones, at approximately 51.1%, while in the Arts category, a modest preference for computers is observed at 50.1%. In the Programming and Science categories, the distribution is nearly even, with a minor tendency towards smartphones in Programming and towards computers in Science.

```{r, echo=FALSE}
device_data <- data %>%
      group_by(CourseCategory, DeviceType) %>%
      summarise(UserCount = n()) %>%
      ungroup()
    
    # Calculate the percentage of users for each device type within each course category
    device_data <- device_data %>%
      group_by(CourseCategory) %>%
      mutate(Percentage = (UserCount / sum(UserCount)) * 100) %>%
      ungroup()
    
    # Create the faceted bar graph
    ggplot(device_data, aes(x = as.factor(DeviceType), y = Percentage, fill = as.factor(DeviceType))) +
      geom_bar(stat = "identity") +
      geom_text(aes(label = paste0(round(Percentage, 1), "%")), vjust = -0.5, size = 3) +  # Add percentage labels on top of bars
      facet_wrap(~ CourseCategory) +
      scale_y_continuous(limits = c(0, 100), labels = scales::percent_format(scale = 1)) +  # Set y-axis limits between 0 and 100
      theme_minimal() +
      labs(title = "Percentage of Users by Device Type Across Course Categories", 
           x = "Device Type", 
           y = "Percentage of Users") +
      theme(axis.text.x = element_text(angle = 0, hjust = 1)) +
      scale_fill_manual(values = c("0" = "#1f77b4", "1" = "#ff7f0e"), 
                        name = "Device Type",
                        labels = c("Device 0", "Device 1"))+
      theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

Overall, this suggests that **students are almost equally likely to use either device type across different courses**, indicating that **both devices are effective for course engagement**. \## Plotting: calculating density to visualise the results

## Plotting: Time spent on course compare to Completaion Rate

The plot reveals that students who completed the course generally spent more time on it, typically above 0.5, with completion rates close to 1.0. However, there is a noticeable density of students who spent considerable time on the course (around 0.5 or higher) but still did not complete it, especially in the Programming and Health categories. These students, despite their effort, have completion rates clustering below 0.5, indicating that time spent alone is not always sufficient for course completion.

```{r, echo=FALSE}
# Calculate densities for not completed and completed data
notcompleted1 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, CompletionRate))

completed1 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, CompletionRate))


highdensity_combined1 <- bind_rows(
  notcompleted1 %>% mutate(Status = "Not Completed"),
  completed1 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion, TimeSpentOnCourse, CompletionRate, density, Status)


# Plot the most dense areas
ggplot(highdensity_combined1, aes(x = TimeSpentOnCourse, y = CompletionRate, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "Time Spent on Course",
       y = "Completion Rate",
       color = "Completion Status") +
  theme_minimal()+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Plotting: Quiz Score compare to Completion Rate

The plot shows a **distinct separation** between students who completed the course and those who did not. Students who **completed the course** typically have **quiz scores above 0.5** and **completion rates close to 1.0**, while those who **did not complete** tend to have **quiz scores below 0.5** and **completion rates under 0.5**. To successfully complete the course, students generally need a quiz score of at least 0.5 and a high completion rate, indicating a **strong link** between **higher quiz scores and consistent course engagement**.

```{r, echo=FALSE}
notcompleted2 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(QuizScores, CompletionRate))

completed2 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(QuizScores, CompletionRate))


highdensity_combined2 <- bind_rows(
  notcompleted2 %>% mutate(Status = "Not Completed"),
  completed2 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion, QuizScores, CompletionRate, density, Status)


# Plot the most dense areas
ggplot(highdensity_combined2, aes(x = QuizScores, y = CompletionRate, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "Quiz scores",
       y = "Completion Rate",
       color = "Completion Status") +
  theme_minimal()+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Plotting: Number of Quiz taken compared to Quiz Score

Students who successfully complete the course generally engage with a higher number of quizzes, often reaching the maximum, and achieve scores above 0.5. However, there is a significant group, particularly in the **Health** and **Programming** categories, who, despite attempting a substantial number of quizzes, fail to complete the course due to lower quiz scores. This indicates that while active participation in quizzes is important, it’s the quality of performance on these quizzes that ultimately determines whether students can successfully complete their courses

```{r, echo=FALSE}
notcompleted3 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(NumberOfQuizzesTaken, QuizScores))

completed3 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(NumberOfQuizzesTaken, QuizScores))


highdensity_combined3 <- bind_rows(
  notcompleted3 %>% mutate(Status = "Not Completed"),
  completed3 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion ,NumberOfQuizzesTaken , QuizScores, density, Status)


# Plot the most dense areas
ggplot(highdensity_combined3, aes(x = NumberOfQuizzesTaken, y = QuizScores, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "Number Of Quizzes Taken",
       y = "Quizzes Scores",
       color = "Completion Status") +
  theme_minimal() +
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )

```

## Plotting: Time spent on course compare to Quiz Score

Across all categories, there is a clear trend where **higher quiz scores** are associated with **course completion**, regardless of the time spent on the course. However, in categories like **Health** and **Programming**, spending **more** time **without** achieving **high** quiz scores still often leads to **non-completion**. Overall, **performing well** on **quizzes** is a more consistent predictor of course completion than the amount of time spent on the course.

```{r, echo=FALSE}
notcompleted4 <- data %>%
  filter(CourseCompletion == '0') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, QuizScores))

completed4 <- data %>%
  filter(CourseCompletion == '1') %>%
  mutate(density = calculate_density(TimeSpentOnCourse, QuizScores))


highdensity_combined4 <- bind_rows(
  notcompleted4 %>% mutate(Status = "Not Completed"),
  completed4 %>% mutate(Status = "Completed")
) %>%
  group_by(CourseCategory, Status) %>%
  filter(density >= quantile(density, 0.8)) %>%
  dplyr:: select(CourseCategory, CourseCompletion ,TimeSpentOnCourse , QuizScores, density, Status)


# Plot the most dense areas
ggplot(highdensity_combined4, aes(x = TimeSpentOnCourse , y = QuizScores, color = Status)) +
  geom_point(alpha = 0.6) +
  facet_wrap(~ CourseCategory, ncol = 3) +
  scale_color_manual(values = c("Completed" = "blue", "Not Completed" = "red")) +
  labs(title = "High-Density Areas by Course Category",
       x = "TimeSpentOnCourse",
       y = "Quizes scores",
       color = "Completion Status") +
  theme_minimal()+
  theme(
    panel.spacing = unit(1, "lines"),  # Add space between panels
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Add border around each panel
  )
```

## Summarize of Plotting

**Higher quiz scores** and **consistent course engagement** (Completion Rate), are the most reliable predictors of course completion across all categories. While time spent on the course and the number of quizzes taken are important, they are not sufficient on their own; students need to achieve scores **above 0.5** to increase their chances of completing the course successfully, particularly in the **Health** and **Programming** categories.


# Conclusions

The analysis shows that **CompletionRate** is consistently the strongest predictor of **CourseCompletion** across different categories, indicating its significant role in course outcomes. In contrast, **TimeSpentOnCourse** has a weaker relationship with course completion. The p-values for most correlations are very low, confirming their statistical significance, except for **DeviceType**, which shows higher p-values and suggests less impact on course completion. Normality tests reveal that all parameters do not follow a perfect normal distribution, which could influence the correlation results. Overall, **CompletionRate** is a key factor in predicting course completion, while **DeviceType** appears less influential.

In general, the percentage of student passing the courses are below 50%, which raises questions about the success of this style of studying. in a follow up research it will be interesting to examine the preferred and better way for education.

# Bibliography

1.Montgomery, C. (2020). *Person Studying Online*. Retrieved from <https://unsplash.com/photos/macbook-pro-displaying-group-of-people-smgTvepind4>. Unsplash License.

2.Romero-Rodríguez, L. M., Ramírez-Montoya, M. S., & Aguaded, I. (2020). Determining factors in MOOCs completion rates: Application test in energy sustainability courses. *Sustainability*, *12*(7), 2893.‏ <https://www.mdpi.com/2071-1050/12/7/2893>

3.Jordan, K. (2015). Massive open online course completion rates revisited: Assessment, length and attrition. *International Review of Research in Open and Distributed Learning*, *16*(3), 341-358. <https://www.erudit.org/en/journals/irrodl/2015-v16-n3-irrodl04980/1065985ar/abstract/>

4.Almeda, M. V., Zuech, J., Utz, C., Higgins, G., Reynolds, R., & Baker, R. S. (2018). Comparing the Factors That Predict Completion and Grades Among For-Credit and Open/MOOC Students in Online Learning. *Online Learning*, *22*(1), 1-18.‏ <https://eric.ed.gov/?id=EJ1179661>

5.Bingol, I., Kursun, E., & Kayaduman, H. (2020). Factors for success and course completion in massive open online courses through the lens of participant types. *Open Praxis*, *12*(2), 223-239.‏ <https://search.informit.org/doi/abs/10.3316/informit.352759430486694>

6.Pechenkina, E., Laurence, D., Oates, G., Eldridge, D., & Hunter, D. (2017). Using a gamified mobile app to increase student engagement, retention and academic achievement. International Journal of Educational Technology in Higher Education, 14(31). <https://doi.org/10.1186/s41239-017-0069-7>

‏

# Additional links

[Kaggle- original dataset](https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset)

[Our github repository](https://github.com/Eran3479/AD_EAE)

```{=html}
<style>
/* Ensure the TOC container is scrollable */
.reveal .toc {
  position: fixed !important; 
  top: 0 !important;
  right: 0 !important;
  width: 300px !important;
  height: 100vh !important;
  overflow-y: auto !important;
  background-color: #f5e8d4 !important;
  border-left: 1px solid #ddd !important;
  padding: 10px !important;
}
/* Background color for the entire presentation */
.reveal {
  background-color: #f5e8d4; /* Light beige-brown-orange */
}

/* Background color for all slides */
.reveal .slides {
  background-color: #f5e8d4; /* Match the overall background */
}

/* Code block background color */
.reveal pre {
  background-color: #f5e8d4 !important; /* Match the slide background */
  color: #333333; /* Dark grey text */
  border-radius: 4px; /* Rounded corners */
  padding: 8px; /* Padding */
  border: 1px solid #ddd; /* Light border */
  overflow-x: auto; /* Horizontal scrolling if needed */
  box-shadow: 0 0 5px rgba(0,0,0,0.1); /* Optional: subtle shadow */
}

/* Code within pre tags */
.reveal code {
  background-color: inherit !important; /* Match the background of pre */
  color: #333333; /* Dark grey text */
}

/* Output blocks background color */
.reveal .output {
  background-color: #f5e8d4 !important; /* Match the slide background */
  color: #333333; /* Dark grey text */
  border: 1px solid #ddd; /* Light border */
  border-radius: 4px; /* Rounded corners */
  padding: 8px; /* Padding */
}

/* Output text color */
.reveal .output pre {
  background-color: #f5e8d4 !important; /* Match the slide background */
  color: #333333; /* Dark grey text */
}

/* Text color adjustment for contrast */
.reveal p, 
.reveal h1, 
.reveal h2, 
.reveal h3 {
  color: #333333; /* Dark grey for readability */
}

/* Smaller title fonts with increased specificity */
.reveal .slides section h1 {
  font-size: 2em !important;
}

.reveal .slides section h2 {
  font-size: 1.2em !important;
}

.reveal .slides section h3 {
  font-size: 1.2em !important;
}

/* Smaller body font */
.reveal .slides section p {
  font-size: 0.8em !important;
}

/* Smaller bullet points */
.reveal .slides section ul {
  font-size: 0.8em !important;
}
</style>
```
